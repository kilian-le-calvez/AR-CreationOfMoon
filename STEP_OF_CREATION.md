# Project Creation Steps

# Goal of the project :
The goald was to make an educationnal AR application. We had to find a theme that could be
teached to a student and make it lively in an AR app so we could explains more easely,
more visually a phenomen.

# Step 0: The idea and the story board !

![storyboard_vir](https://github.com/user-attachments/assets/700b1536-80f6-4933-a9e5-40d3dc5f353b)

The first step was to brainstorm and idea that fit the requirements for the project.
Then the idea was good we made a story board to have a guideline for the animation.

# Step 1: Initial Setup
Set up the Unity project structure and documentation.
Configure the AR application to ensure compatibility and functionality.

<img width="1440" alt="Screenshot 2025-01-12 at 13 35 37" src="https://github.com/user-attachments/assets/c29346d8-1127-4ba5-9cbf-660002660425" />

Using UVCS for synchronizing our work, in unity cloud.

<img width="1440" alt="Screenshot 2025-01-12 at 13 36 02" src="https://github.com/user-attachments/assets/558537c4-50cd-4a0f-9edc-61b70716ebed" />

Using Jira for dispatching our tasks.

# Step 2: Basic Features Implementation

https://github.com/user-attachments/assets/021f75b8-c8ed-4b66-a43a-cabfb9ac7439

Develop a flat surface scanning system to identify and interact with surfaces in the AR environment.
Create basic animations for initial interactions and visual feedback.
Implement a physics-based explosion system to simulate realistic destruction.
Develop a particle attraction system to create dynamic and engaging effects.

# Step 3: Asset Preparation
Search for suitable planet textures to enhance the visual quality of the application.
Combine animations involving explosion, rotation, and attraction to create seamless transitions and effects.

# Step 4: Core Functionality Development
Build the application on a mobile platform to test and validate AR features.
Create an animation recorder system to capture and replay animations dynamically.
Use JSON to trigger and manage animations in the mobile build.
Develop a standalone testing scene for rapid iteration without requiring a full build process.

# Step 5: User Interface and Interaction
Add a UI controller to manage and display text information for voice prompts.
Implement functionality to play voiceovers that read displayed text, enhancing accessibility and immersion.
Develop a menu navigation system with two distinct modes of play to cater to different user preferences.

# Step 6: Advanced Features
Upgrade the environment to improve immersion and realism.
Add UI elements in 3D space to create a more intuitive and interactive user experience.

# Step 7: Project Finalization
Create a repository with a structured README and build files for easy sharing and collaboration.
Document the steps taken throughout the project's development to facilitate future updates and learning.
